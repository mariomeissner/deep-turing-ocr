{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ocr_model_full_tf2.ipynb","provenance":[{"file_id":"1em-PHm1O1I2SvQhC3PTqPg4Nn74BWwvI","timestamp":1553178621035}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZnRkvznkF4Db","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a211eb7c-5aeb-41b6-edf7-b2e8de9b900f","executionInfo":{"status":"ok","timestamp":1572760681213,"user_tz":-540,"elapsed":2435,"user":{"displayName":"Mario Meissner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBSI4QyPAO6EeXnrA1RoUfkaJJEZ2c5DVxUenxnDA=s64","userId":"14555050324477946720"}}},"source":["%tensorflow_version 2.x\n","import os\n","import itertools\n","import codecs\n","import re\n","import datetime\n","import editdistance\n","import pylab\n","import random\n","import editdistance\n","import pickle\n","import json\n","import numpy as np\n","import tensorflow as tf\n","from itertools import cycle\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import *\n","from imageio import imread, imwrite\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from google.colab import drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aZSbJsjFlT11","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"outputId":"5775ad91-7fa7-4e94-d1e8-debf4199b5b9","executionInfo":{"status":"ok","timestamp":1572760887550,"user_tz":-540,"elapsed":21346,"user":{"displayName":"Mario Meissner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBSI4QyPAO6EeXnrA1RoUfkaJJEZ2c5DVxUenxnDA=s64","userId":"14555050324477946720"}}},"source":["drive.mount('/content/gdrive')\n","folder = '/content/gdrive/My Drive/University/tfg/data/numpy_arrays/'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZwo6uxwxJdN","colab_type":"code","colab":{}},"source":["t_images = np.load(folder + \"full/t_images.npy\")\n","t_images2 = np.load(folder + \"batchx.npy\")\n","e_labels = np.load(folder + \"full/e_labels.npy\")\n","e_labels2 = np.load(folder + \"batchye.npy\")\n","label_lens = np.load(folder + \"full/label_lens.npy\")\n","label_lens2 = np.load(folder + \"batchylen.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfTmCfa9GeGW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"91603863-8675-46fc-b531-3dab6cf9322a","executionInfo":{"status":"ok","timestamp":1572760898299,"user_tz":-540,"elapsed":651,"user":{"displayName":"Mario Meissner","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBSI4QyPAO6EeXnrA1RoUfkaJJEZ2c5DVxUenxnDA=s64","userId":"14555050324477946720"}}},"source":["len(t_images), len(e_labels)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1415, 1415)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"njlGiTX9dvB4","colab_type":"code","colab":{}},"source":["# Download and import model file\n","!cp '/content/gdrive/My Drive/University/tfg/model/model.py' .\n","from model import create_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCfUTXupw6sJ","colab_type":"code","colab":{}},"source":["# Take a test set, only from the turing sequences\n","turing_lines = len(t_images)\n","mask = np.full(turing_lines, False)\n","mask[:50] = True\n","np.random.shuffle(mask)\n","t_images_test = t_images[mask]\n","e_labels_test = e_labels[mask]\n","label_lens_test = label_lens[mask]\n","t_images = t_images[~mask]\n","e_labels = e_labels[~mask]\n","label_lens = label_lens[~mask]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTvDzCjs4RKq","colab_type":"code","colab":{}},"source":["def create_model(params, gpu=False):\n","\n","    input_data = Input(name=\"input\", shape=params[\"input_shape\"], dtype=\"float32\")\n","    conv1 = Conv2D(\n","        params[\"conv_filters\"],\n","        params[\"kernel_size\"],\n","        padding=\"same\",\n","        activation=params[\"act\"],\n","        kernel_initializer=\"he_normal\",\n","        name=\"conv1\",\n","    )(input_data)\n","    conv1 = MaxPooling2D(\n","        pool_size=(params[\"pool_size\"], params[\"pool_size\"]), name=\"max1\"\n","    )(conv1)\n","    conv1 = Dropout(0.2)(conv1)\n","    conv2 = Conv2D(\n","        params[\"conv_filters\"],\n","        params[\"kernel_size\"],\n","        padding=\"same\",\n","        activation=params[\"act\"],\n","        kernel_initializer=\"he_normal\",\n","        name=\"conv2\",\n","    )(conv1)\n","    conv2 = MaxPooling2D(\n","        pool_size=(params[\"pool_size\"], params[\"pool_size\"]), name=\"max2\"\n","    )(conv2)\n","    conv2 = Dropout(0.2)(conv2)\n","\n","    # conv1shape = (img_w // (pool_size ** (num_convs - 1)),\n","    #                     (img_h // (pool_size ** (num_convs - 1))) * conv_filters)\n","    conv2shape = (\n","        params[\"img_w\"] // (params[\"pool_size\"] ** params[\"num_convs\"]),\n","        (params[\"img_h\"] // (params[\"pool_size\"] ** params[\"num_convs\"]))\n","        * params[\"conv_filters\"],\n","    )\n","\n","    # Failed attempt to do a skip connection\n","\n","    # conv1 = Reshape(target_shape=conv1shape)(conv1)\n","    # conv2 = Reshape(target_shape=conv2shape)(conv2)\n","    # inner = concatenate([conv1, conv2], axis=2)\n","\n","    inner = Reshape(target_shape=conv2shape, name=\"reshape\")(conv2)\n","\n","    # cuts down input size going into RNN:\n","    inner = Dense(params[\"time_dense_size\"], activation=params[\"act\"], name=\"dense1\")(\n","        inner\n","    )\n","\n","    if gpu:\n","        gru_1 = CuDNNGRU(\n","            params[\"rnn1_size\"],\n","            return_sequences=True,\n","            kernel_initializer=\"he_normal\",\n","            name=\"gru1\",\n","        )(inner)\n","        gru_1b = CuDNNGRU(\n","            params[\"rnn1_size\"],\n","            return_sequences=True,\n","            go_backwards=True,\n","            kernel_initializer=\"he_normal\",\n","            name=\"gru1_b\",\n","        )(inner)\n","    else:\n","        gru_1 = GRU(\n","            params[\"rnn1_size\"],\n","            return_sequences=True,\n","            kernel_initializer=\"he_normal\",\n","            name=\"gru1\",\n","            reset_after=True,\n","            recurrent_activation=\"sigmoid\",\n","        )(inner)\n","        gru_1b = GRU(\n","            params[\"rnn1_size\"],\n","            return_sequences=True,\n","            go_backwards=True,\n","            kernel_initializer=\"he_normal\",\n","            name=\"gru1_b\",\n","            reset_after=True,\n","            recurrent_activation=\"sigmoid\",\n","        )(inner)\n","\n","    gru1_merged = add([gru_1, gru_1b])\n","    # gru_2 =  GRU(rnn2_size, return_sequences=True,\n","    #             kernel_initializer='he_normal',   name='gru2')(gru1_merged)\n","    # gru_2b = GRU(rnn2_size, return_sequences=True, go_backwards=True,\n","    #             kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n","\n","    # transforms RNN output to character activations:\n","    inner = Dense(params[\"output_size\"], kernel_initializer=\"he_normal\", name=\"dense2\")(\n","        #       concatenate([gru_2, gru_2b])\n","        gru1_merged\n","    )\n","\n","    y_pred = Activation(\"softmax\", name=\"softmax\")(inner)\n","    output_labels = Input(\n","        name=\"the_labels\", shape=[params[\"max_string_len\"]], dtype=\"float32\"\n","    )\n","    input_lengths = Input(name=\"input_length\", shape=[1], dtype=\"int64\")\n","    label_lengths = Input(name=\"label_length\", shape=[1], dtype=\"int64\")\n","\n","    # Keras doesn't currently support loss funcs with extra parameters\n","    # so CTC loss is implemented in a lambda layer\n","    # The loss function\n","    def ctc_lambda_func(args):\n","        y_pred, labels, input_length, label_length = args\n","        # the 2 is critical here since the first couple outputs of the RNN\n","        # tend to be garbage:\n","        y_pred = y_pred[:, params[\"ctc_cut\"] :, :]\n","        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n","\n","    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\n","        [y_pred, output_labels, input_lengths, label_lengths]\n","    )\n","\n","    train_model = Model(\n","        inputs=[input_data, output_labels, input_lengths, label_lengths], outputs=loss_out\n","    )\n","\n","    top_k_dec_list, _ = K.ctc_decode(\n","        y_pred[:, params[\"ctc_cut\"] :, :],\n","        K.squeeze(input_lengths, axis=1),\n","        greedy=False,\n","        top_paths=3,\n","    )\n","    decoder0 = K.function([input_data, input_lengths], [top_k_dec_list[0]])\n","    decoder1 = K.function([input_data, input_lengths], [top_k_dec_list[1]])\n","    decoder2 = K.function([input_data, input_lengths], [top_k_dec_list[2]])\n","    decoder_models = decoder0, decoder1, decoder2\n","\n","    return train_model, decoder_models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DAxVPLvg6g8d","colab_type":"code","colab":{}},"source":["len(t_images), len(t_images_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hEYmy-P6y982","colab_type":"code","colab":{}},"source":["t_images = np.concatenate([t_images, t_images2], axis=0)\n","e_labels = np.concatenate([e_labels, e_labels2], axis=0)\n","label_lens = np.concatenate([label_lens, label_lens2], axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGcSyEuZdRTJ","colab_type":"code","colab":{}},"source":["# Invert values (black background, white letters)\n","t_images = 1 - t_images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-k1M7nxhFVPF","colab_type":"code","colab":{}},"source":["t_images.shape, e_labels.shape, label_lens.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACId6hh6oVMi","colab_type":"code","colab":{}},"source":["# # Shuffle and train test split\n","# t_images_train, t_images_test, e_labels_train, e_labels_test, \\\n","#   label_lens_train, label_lens_test =  train_test_split(t_images, \\\n","#   e_labels, label_lens, test_size=0.15, random_state=99)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUrUqKPLi3mE","colab_type":"code","colab":{}},"source":["def unison_shuffled_copies(a, b, c):\n","    assert len(a) == len(b)\n","    p = np.random.permutation(len(a))\n","    return a[p], b[p], c[p]\n","  \n","t_images_train, e_labels_train, label_lens_train = \\\n","  unison_shuffled_copies(t_images, e_labels, label_lens)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qblmL6ujz2AU","colab_type":"code","colab":{}},"source":["# t_images_train, e_labels_train, label_lens_train = \\\n","#   shuffle(t_images, e_labels, label_lens, random_state=99)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMPnxZ5Arx1s","colab_type":"code","colab":{}},"source":["# Load alphabet\n","folder = '/content/gdrive/My Drive/University/tfg/data/numpy_arrays/full/'\n","with open(folder + 'alphabet.pickle', 'rb') as handle:\n","  alphabet = pickle.load(handle)\n","with open(folder + 'ixchar.pickle', 'rb') as handle:\n","  ix_to_char = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5x_QRJYMF4D5","colab_type":"code","colab":{}},"source":["# Define a parameters dictionary\n","params = {}\n","\n","# Data Parameters \n","params['img_h'] = t_images.shape[2]\n","params['img_w'] = t_images.shape[1]\n","params['input_shape'] = (params['img_w'], params['img_h'], 1)\n","params['max_string_len'] = int(max([length for length in label_lens]))\n","\n","# Network parameters\n","params['conv_filters'] = 32\n","params['num_convs'] = 2\n","params['kernel_size'] = (3,3)\n","params['pool_size'] = 2\n","params['time_dense_size'] = 64\n","params['rnn1_size'] = 156\n","params['rnn2_size'] = 256\n","params['ctc_cut'] = 2\n","params['output_size'] = len(alphabet) + 1\n","params['act'] = 'relu'\n","\n","batch_size = 64"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLRKpnQmmlE2","colab_type":"code","colab":{}},"source":["# Save parameters for use in production\n","with open('/content/gdrive/My Drive/University/tfg/model/full/params.json', 'w') as file:\n","  file.write(json.dumps(params, indent=2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pNJNdpgF4D_","colab_type":"code","colab":{}},"source":["# A tensor where all values are the same, is required by ctc loss\n","ctc_input_length = (params['img_w'] // (params['pool_size'] ** params['num_convs'])) - params['ctc_cut']\n","ctc_input_length = np.expand_dims(np.array([ctc_input_length] * len(t_images)), 1)\n","ctc_input_length.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"760sLDZfF4E8","colab_type":"code","colab":{}},"source":["def label_to_text(ixes):\n","  ret = []\n","  for c in ixes:\n","    if c == len(alphabet) or c == -1:  # CTC Blank\n","      ret.append(\"\")\n","    else:\n","      ret.append(ix_to_char[c])\n","  return \"\".join(ret)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImOOiVqwT-FV","colab_type":"code","colab":{}},"source":["# Explore the data, check that everything is correct\n","i = random.randint(0, len(t_images_train)-1)\n","plt.imshow(np.squeeze(t_images_train[i].T), cmap='gray')\n","plt.axis('off')\n","plt.show()\n","print(\"The label is: \", label_to_text(e_labels_train[i]))\n","print(\"Should match: \", label_lens_train[i], len(label_to_text(e_labels_train[i])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jP6szyq4MuQj","colab_type":"code","colab":{}},"source":["# Show all test images\n","for i in range(len(t_images_test)):\n","  plt.imshow(np.squeeze(t_images_test[i].T), cmap='gray')\n","  plt.axis('off')\n","  plt.show()\n","  print(\"The label is: \", label_to_text(e_labels_test[i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgTtTl7uF4En","colab_type":"code","colab":{}},"source":["# Check shapes\n","t_images.shape, e_labels.shape, ctc_input_length.shape, label_lens.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Po4dkyUdh7q","colab_type":"code","colab":{}},"source":["model, decoder_models = create_model(params, gpu=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sisdwWuaunn7","colab_type":"code","colab":{}},"source":["from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","#SVG(model_to_dot(model).create(prog='dot', format='svg'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HduEyto1vZsQ","colab_type":"code","colab":{}},"source":["from keras.utils import plot_model\n","#plot_model(model, to_file='model.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3r0XnglOv1GA","colab_type":"code","colab":{}},"source":["#model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3nupNXVtpNM","colab_type":"code","colab":{}},"source":["# Data Augmentation\n","data_gen_args = dict(\n","    rotation_range = 2,\n","    zoom_range = (1,1.1),\n","    shear_range = 8,\n","    fill_mode = \"constant\",\n","    cval = 0.0,\n","    data_format = 'channels_last',\n",")\n","image_datagen = ImageDataGenerator(**data_gen_args)\n","image_flow = image_datagen.flow(t_images_train, batch_size=1, shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_rav4mDBu0m","colab_type":"code","colab":{}},"source":["def get_data_round():\n","  image_round = []\n","  for _ in range(len(t_images_train)):\n","    image_round.append(np.squeeze(next(image_flow),axis=0))\n","  return [image_round, e_labels_train, ctc_input_length[:len(t_images_train)], \n","          label_lens_train]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PFi-33_3noqN","colab_type":"code","colab":{}},"source":["# Testing the data comming from the generator\n","testing_imgs, testing_lbs, _, _ = get_data_round()\n","r = random.randint(0, len(t_images) - 6)\n","for i in range(r, r+5):\n","  img = testing_imgs[i]\n","  plt.imshow(np.squeeze(img.T), cmap='gray')\n","  plt.axis('off')\n","  plt.show()\n","  print(label_to_text(testing_lbs[i]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEzuuPT1QoFY","colab_type":"code","colab":{}},"source":["# Edit distance metric ...\n","def edit_distance(y_true, y_pred):\n","  total = 0\n","  for true, pred in zip(y_true, y_pred):\n","    true = label_to_text(list(np.squeeze(true)))\n","    pred = label_to_text(list(np.squeeze(pred)))\n","    total += editdistance.eval(true, pred)\n","  return total / len(y_true)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JkDN5GGAF4Ev","colab_type":"code","colab":{}},"source":["number = 16\n","# model.load_weights(f'/content/gdrive/My Drive/University/tfg/model_saves/model_{number}.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XuvBGXTXeW0m","colab_type":"code","colab":{}},"source":["# To name weight files\n","i = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IUU2dBGZEbs","colab_type":"code","colab":{}},"source":["# For plotting\n","losses = []\n","edit_values = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"brkHcHsqF4FG","colab_type":"code","colab":{}},"source":["def print_predictions(show=False, images=t_images_test, labels=e_labels_test):\n","  decoder0, decoder1, decoder2 = decoder_models\n","  # Look at the test results\n","  total_edit_distance = 0\n","  for j in range(len(images)):\n","    decoded0 = np.array(decoder0([images[j:j+1], ctc_input_length[j:j+1]]))\n","    decoded1 = np.array(decoder1([images[j:j+1], ctc_input_length[j:j+1]]))\n","    decoded2 = np.array(decoder2([images[j:j+1], ctc_input_length[j:j+1]]))\n","\n","    if decoded0.size < 2 or decoded1.size < 2 or decoded2.size < 2:\n","      print(\"Predictions are empty\")\n","      break\n","\n","    if show:\n","      plt.imshow(np.squeeze(images[j].T), cmap='gray')\n","      plt.axis('off')\n","      plt.show()\n","      print(\"True label:   \", label_to_text(list(np.squeeze(labels[j]))))\n","      print(\"Prediction 1: \", label_to_text(list(np.squeeze(decoded0))))\n","      print(\"Prediction 2: \", label_to_text(list(np.squeeze(decoded1))))\n","      print(\"Prediction 3: \", label_to_text(list(np.squeeze(decoded2))))\n","    distance = editdistance.eval(label_to_text(labels[j]),\n","                        label_to_text(list(np.squeeze(decoded0))))\n","    total_edit_distance += distance\n","    if show: print(f\"Edit distance: {distance}\")\n","    \n","  average_distance = total_edit_distance / len(images)\n","  print(f\"Average test edit distance: {average_distance}\")\n","  edit_values.append(average_distance)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rf6Vdw9oE1Jv","colab_type":"code","colab":{}},"source":["# Initial fast approximation\n","model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(0.001))\n","history = model.fit(\n","        x = get_data_round(),\n","        y = np.zeros(len(t_images_train)),\n","        batch_size=128,\n","        epochs=10,\n","        verbose=0,\n","        #validation_split=0.15,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASgSr6ltuC1I","colab_type":"code","colab":{}},"source":["# Long training\n","model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr=0.001))\n","for j in range(10):\n","  data_round = get_data_round()\n","  history = model.fit(\n","          x = data_round,\n","          y = np.zeros(len(t_images_train)),\n","          batch_size=64,\n","          epochs=5,\n","          verbose=0,\n","          validation_split=0.2,\n","          shuffle=False,\n","         )\n","  print(f\"Iteration {j:0>2}: loss: {np.min(history.history['loss']):5.2f}, validation loss: {np.min(history.history['val_loss']):5.2f}\")\n","  if (j+1) % 10 == 0:\n","    i += 1\n","    print(f\"Saving weights, model: {i}!\")\n","    model.save_weights(f'/content/gdrive/My Drive/University/tfg/model_saves/modelnew_{i}.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrGVwSnBF4E0","colab_type":"code","colab":{}},"source":["# Long training with test set checking\n","for _ in range(15):\n","  model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr=0.0005))\n","  for j in range(3):\n","    data_round = get_data_round()\n","    history = model.fit(\n","            x = data_round,\n","            y = np.zeros(len(t_images_train)),\n","            batch_size=64,\n","            epochs=5,\n","            verbose=0,\n","           )\n","    losses.extend(history.history['loss'])\n","    print(f\"Iteration {j:0>2}: loss: {np.min(history.history['loss']):5.2f}\")\n","  print_predictions()\n","#   if (j+1) % 10 == 0:\n","#     i += 1\n","#     print(f\"Saving weights, model: {i}!\")\n","#     model.save_weights(f'/content/gdrive/My Drive/University/tfg/model_saves/modelnew_{i}.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWA2O1vDxLFk","colab_type":"code","colab":{}},"source":["print_predictions(show=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"doQGbjBX87YI","colab_type":"code","colab":{}},"source":["print_predictions(show=True, images=t_images_train[:20], labels=e_labels_train[:20])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rreBLVvebIlH","colab_type":"code","colab":{}},"source":["edit_values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_VO5uzfaoBy","colab_type":"code","colab":{}},"source":["# Plot graphcs\n","plt.plot(losses)\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.show()\n","\n","plt.plot(edit_values)\n","plt.title('edit distance')\n","plt.ylabel('edit distance')\n","plt.xlabel('epoch / 15')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_BkrM5t_RJrt","colab_type":"code","colab":{}},"source":["# i += 1\n","# print(f\"Saving weights, model: {i}!\")\n","# model.save_weights(f'/content/gdrive/My Drive/University/tfg/model_saves/model_{i}.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhT_gr5UBxVd","colab_type":"code","colab":{}},"source":["# Save final model for production\n","model.save_weights('/content/gdrive/My Drive/University/tfg/model/full/weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOyBb_rK6hSM","colab_type":"code","colab":{}},"source":["# Load production weights\n","# model.load_weights('/content/gdrive/My Drive/University/tfg/backend/weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a40r5ghZJZMc","colab_type":"code","colab":{}},"source":["# Compute training dataset edit distance\n","decoder0, decoder1, decoder2 = decoder_models\n","total_edit_distance = 0\n","for j in range(len(t_images_train)):\n","  decoded0 = decoder0([t_images_train[j:j+1], ctc_input_length[j:j+1]])[0]\n","  true = label_to_text(list(np.squeeze(e_labels_train[j])))\n","  if decoded0.size:\n","    predicted = label_to_text(list(np.squeeze(decoded0, axis=0)))\n","  else:\n","    predicted = \"\"\n","  distance = editdistance.eval(true, predicted)\n","  total_edit_distance += distance\n","  \n","print(f\"Average training edit distance: {total_edit_distance / len(t_images_train)}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wXc__n8Kb7u","colab_type":"code","colab":{}},"source":["# # Compute training dataset edit distance (in batch, WIP)\n","# total_edit_distance = 0\n","# decoded0 = decoder0([t_images_train, ctc_input_length[:len(t_images_train)]])[0]\n","# trues = []\n","# preds = []\n","# for label in list(np.squeeze(e_labels_train[j])):\n","#   trues.append(label_to_text(label))\n","# for dec in decoded0:\n","#   preds.append(label_to_text(list(dec)))\n","\n","# for true, pred in trues, preds:\n","#   distance = editdistance.eval(true, pred)\n","#   total_edit_distance += distance\n","  \n","# print(f\"Average edit distance: {total_edit_distance / len(t_images_train)}\")"],"execution_count":0,"outputs":[]}]}